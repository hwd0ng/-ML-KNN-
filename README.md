## KNN이란
- 간단하면서도 효과적인 머신러닝 분류 및 회귀 알고리즘

#### 1. 기본 개념
새로운 데이터 포인트를 분류할 때, 주변의 가장 가까운 K개의 이웃 데이터 포인트를 참조합니다.
이웃들의 클래스를 바탕으로 새 데이터의 클래스를 결정합니다.

#### 2. 작동 방식
- 거리 계산: 새 데이터 포인트와 모든 학습 데이터 간의 거리를 계산합니다.
- K개 선택: 가장 가까운 K개의 이웃을 선택합니다.
- 투표: 이웃들의 클래스 중 다수결로 새 데이터의 클래스를 결정합니다.

#### 3. 거리 측정
- 주로 유클리드 거리를 사용하지만, 맨해튼 거리나 민코프스키 거리 등도 사용 가능합니다.

#### 4. K 값 선택
- K가 작으면 노이즈에 민감하고, 크면 경계가 모호해집니다.
- 일반적으로 홀수를 선택하여 동점을 피합니다.
- 교차 검증을 통해 최적의 K를 선택할 수 있습니다.


#### 5. 장점:
- 구현이 간단하고 이해하기 쉽습니다.
- 학습 과정이 없어 빠릅니다.
- 새로운 데이터를 쉽게 추가할 수 있습니다.


#### 6. 단점:
- 대규모 데이터셋에서는 계산 비용이 높습니다.
- 특성의 스케일에 민감합니다.
- 고차원 데이터에서 성능이 저하될 수 있습니다.


#### 7. 응용 분야:
- 추천 시스템
- 이미지 분류
- 금융 분야의 신용 평가

KNN은 간단하지만 효과적인 알고리즘으로, 특히 데이터의 분포나 관계를 잘 모를 때 유용하게 사용될 수 있습니다. 다만, 데이터의 특성과 규모에 따라 다른 알고리즘이 더 적합할 수 있으므로, 문제에 따라 적절히 선택해야 합니다.

#### [▶︎ 이론 및 실습](https://github.com/hwd0ng/ML_KNN/blob/main/KNN_%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8.ipynb)
